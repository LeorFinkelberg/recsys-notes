Латентная модель: по данным $D$ оцениваются векторы:
- $(p_tu)_{t \in G}$ -- профили пользователей $u \in U, |G| \ll |I|$,
- $(q_{ti})_{t \in H}$ -- профили объектов $i \in I, |H| \ll |U|$.

Если очень грубо, то все латентные модели можно разбить на три группы:
- _Ко-кластеризация_ (би-кластеризация):
	- жесткая:
	 $$
	 \begin{cases}
	   p_{tu} = \text{пользователь} \, u \, \text{принадлежит кластеру} \, t \in G,\\
	   q_{ti} = \text{объект} \, i \, \text{принадлежит кластеру} \, t \in H
     \end{cases}
       $$
	- мягкая: $p_{tu}, q_{ti}$ -- степени принадлежности кластерам.
- _Матричные разложения_: $G \equiv H$; по $p_{tu}, q_{ti}$ должны восстанавливаться $r_{ui}$,
- _Вероятностные модели_: $G \equiv H$; $p_{tu} = p(t|u), q_{ti} = q(t|i)$.
### Матричные разложения

$T$ -- множество тем (интересов): $|T| \ll |U|, |T| \ll |I|$;
$p_{tu}$ -- неизвестный профиль клиента $u$; $P = (p_{tu})_{ |T| \times |U| }$; 
$q_{ti}$ -- неизвестный профиль объекта $i$; $Q = (q_{ti})_{ |T| \times |I| }$.

Задача: найти разложение $r_{ui} = \sum_{t \in T} \pi_t p_{tu} q_{ti}$.
Матричная запись: $R = P^T \Delta Q, \, \Delta = \text{diag}(\pi_1, \ldots, \pi_{ |T| })$. 

Методы решения:
- SVD -- сингулярное разложение,
- NNMF -- неотрицательная матричная факторизация, $p_{tu} \geq 0, \, q_{ti} \geq 0$,
- PLSA -- вероятностный латентный семантический анализ.

Latent Factor Model - вариация сингулярного разложения, которая не требует знания всех элементов матрицы взаимодействий [[Список литературы#^55addb]].

Явные предпочтения (explicit) $r_{ui}$ (более качественные данные):
- покупки товаров в магазине,
- оценки, рейтинги, лайки/дизлайки

Неявные предпочтения (implicit) $s_{ui}$ (большой объем данных):
- посещение страницы товара,
- просмотр (какой-то части) фильма

Идея: предсказываем $s_{ui}$ с весом $c_{ui} = 1 + \alpha \, r_{ui}$
$$
\sum_{(u,i) \in D} c_{u,i} \, \big( s_{ui} - \bar{s}_u - \bar{s}_i - \sum_{t \in T} p_{tu} q_{ti} \big)^2 + \lambda \sum_{u \in U} \| p_u \|^2 + \mu \sum_{i \in I} \| q_i \|^2 \rightarrow \min_{P,Q}
$$

