Рекомендательные системы часто для улучшения прогнозов используют текстовое описание объектов, особенно в сценариях холодного старта или Zero-Shot-рекомендаций, в которых подходы классической колаборативной фильтрации не работают. В последние годы было предложено множество подходов к анализу побочной текстовой информации. Однако, эти модели обучены предсказывать семантическое сходство без использования данных о взаимодействии латентных (скрытых) паттернов, специфичных для рекомендательных систем.

В статье предлагается фреймворк для обучения трансформеров на последовательностях, учитывающих взаимодействие данных. Авторы показывают, что модели, обученные с помощью beeFormer, могут переносить знания (transfer knowledge) между наборами данных, превосходя при этом не только трансформеры на последовательностях предложений, но еще и классические методы коллаборативной фильтрации.

Также авторы показывают, что обучение на нескольких наборах данных из различных доменов аккумулирует знания, открывая возможность обучения универсальных, не привязанных к домену моделей.

За последние годы было предложено много множество подходов к построению алгоритмов для рекомендательных систем, наиболее популярным из которых является коллаборативная фильтрация. Методы коллаборативной фильтрации предсказывают (фильтруют) предпочтения пользователей, анализируя их прошлые взаимодействия. 

К популярным методам коллаборативной фильтрации относятся:
- методы на базе ближайших соседей,
- методы матричного разложения,
- глубокие сети,
- неглубокие линейные автокодировщики.

Неглубокие линейные автокодировщики стали популярны недавно, главным образом потому, что модель EASE имеет решение в замкнутом виде и при этом обладает высокой производительностью, сравнимой с глубокими моделями.

Поскольку EASE не может масштабироваться для наборов данных с большим количеством айтемов, были предложены масштабируемые варианты:
- SANSE,
- ELSA.

SANSA сохраняет оригинальную структуру EASE, но использует (разреженную) неполную факторизацию Холецкого, приближающую обратную матрицу $X^TX$ для построения асимметричной аппроксимации матрицы весов item-to-item.

ELSA с другой стороны приближает выученную матрицу весов item-to-item с помощью низкоранговой аппроксимации $W = AA^T$, где $diag(W) = 0$ чтобы избежать тривиальных решений.

Несмотря на популярность и эффективность методов коллаборативной фильтрации в рекомендательных системах, они не могут строить прогнгозы при отсутствии взаимодействий.

В сценариях холодного старта и Zero-Shot рекомендаций можно использовать фильтрацию на основе контента, используя дополнительную информацию (атрибуты, картинки, текст и тд) непосредственно для создания рекомендаций или для выучивания функций преобразования переводящих дополнительную информацию в представления для моделей коллаборативной фильтрации.

Использование текстовой модальности (описание айтемов, отзывов пользователей etc.) в качестве дополнительной информации стало очень популярным после появления трансформеров. 

Модели трансформеров могут быть использованы для кодирования текста в векторное представление, а Sentence Transforms были специально разработаны для получения латентных представлений текста из текстовых блоков (предложений, абзацев), которые затем могут быть использованы для решения различных задач рекомендаций.

Однако, Sentence Transformers обученные предсказывать семантическую близость, часто не могут выявить поведенческие паттерны пользователей, скрытые во взаимодействиях пользователи с контентом.

Чтобы закрыть зазор между семантической близостью и близостью по взаимодействию, авторы предлагают следующую идею: по-прежнему использовать обучающую процедуру модели ELSA, но вместо оптимизации матрица $A$, генерировать матрицу $A$ с помощью модели Sentence Transformer и оптимизировать его параметры вместо прямой оптимизации матрицы $A$.

Однако у этого подхода есть один очень серьезный недостаток. На каждом шаге обучения приходится генерировать и оптимизировать представления для всех айтемов в наборе, что приводит к огромным по размеру пакетам (порядка миллиона).

Эту проблему авторы предлагают решать с помощью 3 техник:
- градиентной контрольной точки,
- аккумуляции градиента,
- отрицательной выборки.

Комбинируя эти три техники, Sentence Transformer и процедуру обучения ELSA, авторы предлагают фреймворк beeFormer, который использует дополнительную текстовую модальность и взаимодействия напрямую для обновления параметров трансформера.

Авторы утверждают, что Sentence Transformer, обученный с помощью beeFormer, превосходит по производительности все baselines для сценариев холодного старта и zero-shot рекомендаций.

Также авторы показывают, что модели, обученные на комбинации наборов данных из различных доменов повышают производительность рекомендательных моделей не привязанных к домену. 

Процедура обучения начинается с генерации латентных представлений по айтемам -- это матрица $A$
$$
A = g(\mathbb{T}, \theta_g).
$$

Теперь можно вычислить потери
$$
L = || \, \text{norm} X_u - \text{norm} \Big( A \, A^T - \mathcal{I}\Big) \, ||_F^2.
$$
И наконец, можно посчитать градиенты от $L$ по $A$ , а затем градиенты по $\theta_g$ цепным правилом.

Однако, при использовании фреймворков дифференциирования общего назначения (PyTorch, Tensorflow etc.) возникают проблемы, связанные с размещением градиентов $\theta_g$ в памяти, потому как размер матрицы $A$ определяется мощностью множества _всех_ айтемов.

Авторы эту проблему предлагают решать так:
- Сначала они вычисляют матрицу $A$ пакетами без отслеживания градиентов $\theta_g$ .
- Затем они вычисляют прогнозы, потери для пакета пользователей $X_u$  и контрольные точки градиентов для матрицы $A$. 
- И, наконец, вычисляется матрица $A$ снова пакетами и используются контрольные точки градиентов для вычисления градиентов $\theta_g$.
- Потом градиенты аккумулируются в цикле и обновляются с помощью PyTorch.

Матрица взаимодействий $X$ обычно очень разрежена. На практике это означает, что нам вообще говоря не нужно кодировать все айтемы в матрице $A$.

Более формально. Пусть $\mathbb{I}_b$ это подмножество множества $\mathbb{I}$, полученное из взаимодействий, представленных в случайной выборке, отобранной из матрицы $X$.

Авторы отмечают, что значительное повышение производительности при обучении моделей коллаборотивной фильтрации может быть достигнуто с помощью отрицательной выборки.

Отрицательную выборку авторы реализовали через случайный отбор айтемов в подмножество $\mathbb{I}_b$ и фиксацию общего числа айтемов на каждом шаге обучения $m$.

Параметр $m$ становится дополнительным гиперпараметром $|\mathbb{I}_b| \leqslant m << |\mathbb{I}|$. В случае, когда $m$ оказывается строго больше $|\mathbb{I}_b|$, авторы предлагают выбирать случайным образом $m - |\mathbb{I}_b|$ айтемов и добавлять их в пакет с нулями в соответствующих столбцах.

Заметным преимуществом beeFormer является то, что асимптотическая сложность алгоритма зависит не от мощности множества айтемов, а только от гиперпараметра $m$.

Авторы оценивали beeFormer на нескольких популярных наборах данных: MovieLens20M, Goodbooks-10k и Amazon Books.

Из набора данных удаляются айтемы без описания. Затем авторы используют Meta-Llama-3.1-8B-Instruct для генерации стандартизированных описаний айтемов для обучения модели.

Авторы используют две конфигурации экспериментов. Первая для проверки обобщающей способности модели. Здесь набор ML20M разделяется на две части. 2000 случайно выбранных айтемов они оставляют под тест, а на остальных делают перекрестную проверку и обучают модели.



