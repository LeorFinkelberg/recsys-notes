Для Олега Лашинина модели рекомендаций начинаются с тех, которые можно построить на данных формата `(user_id, item_id, timestamp)`. Если такие данные, то с помощью следующих моделей можно составить список персональных рекомендаций для каждого пользователя внутри датасета.
1. [iALS](https://www.researchgate.net/profile/Yifan-Hu-25/publication/220765111_Collaborative_Filtering_for_Implicit_Feedback_Datasets/links/0912f509c579ddd954000000/Collaborative-Filtering-for-Implicit-Feedback-Datasets.pdf) (2008) -- масштабируемая на большие объемы матричная факторизация. Крупные компании в РФ часто упоминают ее как кандидатогенератор.
2. [EASE](https://arxiv.org/pdf/1905.03375) (2019) -- один гиперпараметр, решение в явном виде. Моделька -- матрица весов item-2-item. Топ-1 модель по мнению авторов из Сбера. Ее минус -- большие каталоги айтемов, но на них можно использовать [ELSA](https://web.archive.org/web/20220920175938id_/https://dl.acm.org/doi/pdf/10.1145/3523227.3551482) или [SANSA](https://dl.acm.org/doi/abs/10.1145/3604915.3608827).
3. SLIM (2011) -- аналог EASE. Матрица весов разреженная, зависимость от гиперпараметров более сильная, их больше. По качеству SLIM похуже EASE. С ней возится сложнее. Однако, в силу разреженности матрицы, SLIM весит около 100 Кб, а EASE 600 Мб при прочих равных.
4. [MultiVAE](https://dl.acm.org/doi/pdf/10.1145/3178876.3186150) (2018) -- модель от Netflix. На вход модель принимает только вектор взаимодействий. Поэтому ее можно обучить на 1000 пользователей, а инференс делать на 100 000 ==без дообучения==!!!
5. [ItemKNN](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=46a4c108f8ff7bde72a4dc57579f560222c2d53a) (2001) -- старенькая модель, но довольно неплохая (рано списывать со счетов).
6. [GRU4Rec](https://arxiv.org/abs/1511.06939) (2015). Наиболее популярные ошибки в реализации разобраны [здесь](https://arxiv.org/pdf/2307.14956).
7. [SASRec](https://arxiv.org/pdf/1808.09781) (2018) -- трансформер для next-item recommendation.
8. [BERT4Rec](http://ofey.me/papers/BERT4Rec.pdf) (2019). Чуть лучше чем SASRec (см. https://arxiv.org/pdf/2207.07483). По опыту, часто нет смысла использовать SASRec и BERT4Rec вместе. Лучше выбрать что-то одно.
9. [LightGCN](https://arxiv.org/pdf/2002.02126) (2020) -- графовая сверточная сеть. В графе есть только пользователи и айтемы. Модель оценивает связи пользователь-айтем и делает рекомендации. Громоздкая, медленно обучаемая и негибкая модель. Значительно лучше вариация [GFCF](https://arxiv.org/pdf/2108.07567) (2021).
10. [TIFU KNN](https://arxiv.org/pdf/2006.00556) (2020). Если в данных есть повторные действия между пользователями и айтамами (например, покупки в супермаркетах), то скорее всего все модели выше проиграют по качеству TIFU KNN. Эта модель вокруг персональной частоты покупок пользователя. Если человек купил 100 раз молоко, именно TIFU KNN без проблем порекомендует его 101 раз и не ошибется. Остальные модели могут повторить персональные частоты, но все равно по качеству уступят TIFU KNN. 

Есть еще модели от Pinterest (GraphSAGE/PinSAGE).
